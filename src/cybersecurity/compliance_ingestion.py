"""
Compliance Framework Document Ingestion Module with LLM Processing

This module provides advanced document processing using LLM to extract structured
compliance data and map it to the unified schema. It creates nodes for:
- RegulatoryBody
- Framework
- Control
- Industry
And establishes relationships including Control->Technique mappings.

Features:
- LLM-based document analysis and structured data extraction
- Schema-compliant node creation (RegulatoryBody, Framework, Control, Industry)
- ATT&CK technique mapping for controls
- Intelligent relationship establishment
- Progress tracking and validation
"""

import hashlib
import json
import os
import uuid
from datetime import datetime
from typing import Any, Dict, List, Tuple

import PyPDF2
import streamlit as st

from src.api.llm_service import get_llm


class ComplianceIngestion:
    """
    Compliance framework document ingestion with LLM-based extraction.

    Processes documents to extract structured compliance data and creates
    schema-compliant nodes according to the unified cybersecurity model.
    """

    def __init__(self):
        """Initialize the compliance ingestion system."""
        self.llm = get_llm()

    def ingest_document_with_llm(self, graph, file_path: str) -> Tuple[bool, str, Dict]:
        """
        Ingest a compliance framework document using LLM for structured extraction.
        The LLM automatically detects framework type and industry from the document.

        Args:
            graph: Neo4j database connection
            file_path: Path to the PDF document

        Returns:
            Tuple of (success, message, stats)
        """
        try:
            # Extract document metadata
            doc_metadata = self._extract_document_metadata(file_path)

            # Seed/ensure a placeholder Document node to avoid property warnings and detect duplicates
            status = self._ensure_document_placeholder(graph, doc_metadata)
            if status == "ingested":
                return False, "Document already ingested", {}

            # Extract text content from PDF
            st.info("ðŸ“„ Extracting text from PDF...")
            content = self._extract_pdf_content(file_path)
            if not content:
                return False, "Failed to extract content from PDF", {}

            # Use LLM to analyze document and auto-detect framework type and industry
            st.info("ðŸ¤– Analyzing document to detect framework type and industry...")
            document_analysis = self._analyze_document_with_llm(content)

            if not document_analysis:
                return False, "Failed to analyze document structure", {}

            framework_type = document_analysis.get(
                "framework_type", "Unknown Framework"
            )
            industry = document_analysis.get("industry", "General")

            st.info(f"ðŸŽ¯ Detected: {framework_type} framework for {industry} industry")

            # Use LLM to extract structured compliance data
            st.info("ðŸ¤– Processing document with LLM for structured extraction...")
            extracted_data = self._extract_structured_data_with_llm(
                content, framework_type, industry
            )

            if not extracted_data:
                return False, "Failed to extract structured data from document", {}

            # Create schema nodes and relationships
            st.info("ðŸ—ï¸ Creating knowledge graph nodes and relationships...")
            ingestion_stats = self._create_schema_compliant_nodes(
                graph, extracted_data, doc_metadata, framework_type, industry
            )

            # Map controls to ATT&CK techniques
            st.info("ðŸ”— Mapping controls to ATT&CK techniques...")
            technique_mappings = self._map_controls_to_techniques(
                graph,
                extracted_data.get("controls", []),
                framework_type=framework_type,
                industry=industry,
            )
            ingestion_stats["technique_mappings"] = technique_mappings
            # Ensure at least one mapping exists overall; try regex-based fallback
            if technique_mappings == 0:
                fallback_mappings = self._fallback_map_controls(
                    graph, extracted_data.get("controls", []), framework_type, industry
                )
                ingestion_stats["technique_mappings"] += fallback_mappings

            # Reflect created MITIGATES links in relationships_created metric for UI
            if "relationships_created" not in ingestion_stats:
                ingestion_stats["relationships_created"] = 0
            ingestion_stats["relationships_created"] += ingestion_stats.get(
                "technique_mappings", 0
            )

            # Update ingestion status
            self._update_ingestion_status(framework_type, doc_metadata, ingestion_stats)

            return (
                True,
                f"Successfully processed {framework_type} framework with {ingestion_stats.get('controls_count', 0)} controls",
                ingestion_stats,
            )

        except Exception as e:
            st.error(f"Error during LLM-based ingestion: {str(e)}")
            return False, f"Error processing document: {str(e)}", {}

    def _analyze_document_with_llm(self, content: str) -> Dict[str, Any]:
        """
        Use LLM to analyze document and automatically detect framework type and industry.

        Args:
            content: Document text content

        Returns:
            Dictionary containing detected framework type and industry
        """
        try:
            # Create analysis prompt to detect framework and industry
            analysis_prompt = f"""
            You are a cybersecurity compliance expert. Analyze the following document content to automatically detect the framework type and target industry.

            Document Content (first 10,000 characters):
            {content[:10000]}

            Based on this content, determine:

            1. **Framework Type**: What specific compliance framework or standard is this document about?
               Possible types include but are not limited to:
               - NIST Cybersecurity Framework
               - HIPAA (Health Insurance Portability and Accountability Act)
               - PCI-DSS (Payment Card Industry Data Security Standard)
               - CIS Controls (Center for Internet Security)
               - ISO 27001
               - SOC 2 (Service Organization Control 2)
               - FedRAMP (Federal Risk and Authorization Management Program)
               - GDPR (General Data Protection Regulation)
               - COBIT (Control Objectives for Information and Related Technologies)
               - FISMA (Federal Information Security Management Act)
               - Or identify if it's another specific framework

            2. **Primary Industry**: What industry is this framework primarily targeting?
               Common industries include:
               - Healthcare
               - Financial Services
               - Government
               - Retail/E-commerce
               - Technology
               - Manufacturing
               - Education
               - Energy/Utilities
               - General (if applicable to multiple industries)

            Return your analysis in this exact JSON format:
            {{
                "framework_type": "Detected Framework Name",
                "industry": "Primary Target Industry",
                "confidence": "high|medium|low",
                "reasoning": "Brief explanation of detection reasoning"
            }}

            Look for specific keywords, terminology, control structures, and regulatory language that indicate the framework type and industry focus.
            """

            # Get LLM response
            response = self.llm.invoke(analysis_prompt)

            # Handle different response types
            if hasattr(response, "content"):
                response_text = response.content
            elif isinstance(response, list) and len(response) > 0:
                response_text = str(response[0])
            else:
                response_text = str(response)

            # Ensure response_text is a string
            if not isinstance(response_text, str):
                response_text = str(response_text)

            # Parse JSON response
            try:
                # Clean up response to extract JSON
                if "```json" in response_text:
                    json_start = response_text.find("```json") + 7
                    json_end = response_text.find("```", json_start)
                    response_text = response_text[json_start:json_end].strip()
                elif "```" in response_text:
                    json_start = response_text.find("```") + 3
                    json_end = response_text.find("```", json_start)
                    response_text = response_text[json_start:json_end].strip()

                analysis_result = json.loads(response_text)

                # Validate and set defaults if needed
                framework_type = analysis_result.get(
                    "framework_type", "Unknown Framework"
                )
                industry = analysis_result.get("industry", "General")
                confidence = analysis_result.get("confidence", "medium")
                reasoning = analysis_result.get("reasoning", "Automatic detection")

                st.info(f"ðŸŽ¯ Detection confidence: {confidence} - {reasoning}")

                return {
                    "framework_type": framework_type,
                    "industry": industry,
                    "confidence": confidence,
                    "reasoning": reasoning,
                }

            except json.JSONDecodeError:
                st.warning("âš ï¸ Could not parse LLM analysis, using fallback detection")
                # Fallback analysis using keywords
                return self._fallback_framework_detection(content)

        except Exception as e:
            st.warning(f"âš ï¸ LLM analysis failed: {str(e)}, using fallback detection")
            return self._fallback_framework_detection(content)

    def _fallback_framework_detection(self, content: str) -> Dict[str, Any]:
        """
        Fallback framework detection using keyword matching.

        Args:
            content: Document text content

        Returns:
            Dictionary containing detected framework type and industry
        """
        content_lower = content.lower()

        # Framework detection keywords
        framework_keywords = {
            "NIST Cybersecurity Framework": ["nist", "cybersecurity framework", "csf"],
            "HIPAA": [
                "hipaa",
                "health insurance portability",
                "protected health information",
                "phi",
            ],
            "PCI-DSS": ["pci", "payment card industry", "cardholder data", "pci dss"],
            "CIS Controls": [
                "cis controls",
                "center for internet security",
                "critical security controls",
            ],
            "ISO 27001": ["iso 27001", "information security management", "isms"],
            "SOC 2": ["soc 2", "service organization control", "aicpa"],
            "FedRAMP": ["fedramp", "federal risk authorization", "cloud security"],
            "GDPR": ["gdpr", "general data protection regulation", "personal data"],
            "FISMA": ["fisma", "federal information security", "fips"],
            "COBIT": ["cobit", "control objectives", "information technology"],
        }

        # Industry detection keywords
        industry_keywords = {
            "Healthcare": ["healthcare", "medical", "patient", "hospital", "clinic"],
            "Financial Services": ["financial", "bank", "credit", "payment", "trading"],
            "Government": ["federal", "government", "agency", "public sector"],
            "Retail": ["retail", "e-commerce", "merchant", "shopping"],
            "Technology": ["technology", "software", "cloud", "saas"],
            "Manufacturing": ["manufacturing", "industrial", "production"],
            "Education": ["education", "university", "school", "academic"],
        }

        # Detect framework
        detected_framework = "Unknown Framework"
        for framework, keywords in framework_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                detected_framework = framework
                break

        # Detect industry
        detected_industry = "General"
        for industry, keywords in industry_keywords.items():
            if any(keyword in content_lower for keyword in keywords):
                detected_industry = industry
                break

        return {
            "framework_type": detected_framework,
            "industry": detected_industry,
            "confidence": (
                "medium" if detected_framework != "Unknown Framework" else "low"
            ),
            "reasoning": "Keyword-based detection",
        }

    def _extract_structured_data_with_llm(
        self, content: str, framework_type: str, industry: str
    ) -> Dict[str, Any]:
        """
        Use LLM to extract structured compliance data from document content.

        Args:
            content: Document text content
            framework_type: Type of compliance framework
            industry: Target industry

        Returns:
            Dictionary containing structured compliance data
        """
        try:
            # Create comprehensive prompt for structured extraction
            extraction_prompt = f"""
            You are a cybersecurity compliance expert. Analyze the following {framework_type} document content and extract structured information to create a comprehensive compliance knowledge graph.

            Document Content:
            {content[:15000]}  # Limit content to avoid token limits

            Please extract and structure the following information in JSON format:

            1. **Regulatory Body Information**:
            - Name of the regulatory organization/body that published this framework
            - Description of the organization
            - Official website or authority information (if mentioned)

            2. **Framework Information**:
            - Official framework name
            - Version/revision information
            - Publication date (if mentioned)
            - Framework description/purpose
            - Scope and applicability

            3. **Industry Information**:
            - Primary target industry: {industry}
            - Additional applicable industries (if mentioned)
            - Industry-specific requirements or variations

            4. **Controls Extraction**:
            For each control/requirement found, extract:
            - Control ID/number (if available)
            - Control name/title
            - Detailed description
            - Control type (preventive, detective, corrective, etc.)
            - Implementation guidance
            - Related sub-controls (if any)
            - Potential ATT&CK techniques this control could mitigate (make educated mappings based on control description)

            Return the response in this exact JSON structure:
            {{
                "regulatory_body": {{
                    "name": "string",
                    "description": "string",
                    "authority_type": "string"
                }},
                "framework": {{
                    "name": "string",
                    "version": "string",
                    "description": "string",
                    "publication_date": "string",
                    "scope": "string"
                }},
                "industry": {{
                    "primary_industry": "{industry}",
                    "applicable_industries": ["list of industries"],
                    "industry_specific_notes": "string"
                }},
                "controls": [
                    {{
                        "control_id": "string",
                        "name": "string", 
                        "description": "string",
                        "control_type": "string",
                        "implementation_guidance": "string",
                        "potential_attack_techniques": ["T1001", "T1055", "etc"],
                        "sub_controls": ["list of sub-control descriptions"]
                    }}
                ]
            }}

            Focus on extracting comprehensive, actionable control information that can be mapped to cybersecurity threats and ATT&CK techniques.
            """

            # Use LLM to extract structured data
            response = self.llm.invoke(extraction_prompt)

            # Parse JSON response
            try:
                # Clean up response to extract JSON
                response_text = ""
                if hasattr(response, "content"):
                    response_text = str(response.content)
                else:
                    response_text = str(response)

                # Find JSON in response
                start_idx = response_text.find("{")
                end_idx = response_text.rfind("}") + 1

                if start_idx != -1 and end_idx != -1:
                    json_str = response_text[start_idx:end_idx]
                    extracted_data = json.loads(json_str)

                    # Validate required fields
                    if all(
                        key in extracted_data
                        for key in [
                            "regulatory_body",
                            "framework",
                            "industry",
                            "controls",
                        ]
                    ):
                        return extracted_data
                    else:
                        st.warning(
                            "âš ï¸ Incomplete data extraction, using fallback structure"
                        )
                        return self._create_fallback_structure(
                            framework_type, industry, content
                        )
                else:
                    st.warning("âš ï¸ No JSON found in response, using fallback structure")
                    return self._create_fallback_structure(
                        framework_type, industry, content
                    )

            except json.JSONDecodeError as e:
                st.warning(f"âš ï¸ JSON parsing error: {e}, using fallback extraction")
                return self._create_fallback_structure(
                    framework_type, industry, content
                )

        except Exception as e:
            st.error(f"Error in LLM extraction: {e}")
            return self._create_fallback_structure(framework_type, industry, content)

    def _create_fallback_structure(
        self, framework_type: str, industry: str, content: str
    ) -> Dict[str, Any]:
        """Create a basic fallback structure when LLM extraction fails."""
        return {
            "regulatory_body": {
                "name": f"{framework_type} Authority",
                "description": f"Regulatory body responsible for {framework_type}",
                "authority_type": "Standards Organization",
            },
            "framework": {
                "name": framework_type,
                "version": "1.0",
                "description": f"{framework_type} compliance framework",
                "publication_date": datetime.now().strftime("%Y"),
                "scope": f"{industry} industry compliance",
            },
            "industry": {
                "primary_industry": industry,
                "applicable_industries": [industry],
                "industry_specific_notes": f"Framework applicable to {industry} sector",
            },
            "controls": [
                {
                    "control_id": "GEN-001",
                    "name": "General Compliance Control",
                    "description": f"Basic compliance control extracted from {framework_type}",
                    "control_type": "Preventive",
                    "implementation_guidance": "Implement according to framework guidelines",
                    "potential_attack_techniques": [],
                    "sub_controls": [],
                }
            ],
        }

    def _create_schema_compliant_nodes(
        self,
        graph,
        extracted_data: Dict,
        doc_metadata: Dict,
        framework_type: str,
        industry: str,
    ) -> Dict[str, int]:
        """
        Create schema-compliant nodes and relationships according to the unified model.

        Creates: Document, RegulatoryBody, Framework, Control, Industry nodes
        Establishes: All required relationships per schema
        """
        stats = {
            "regulatory_bodies": 0,
            "frameworks": 0,
            "controls": 0,
            "industries": 0,
            "technique_mappings": 0,
            "controls_count": 0,
            "relationships_created": 0,
        }

        try:
            # 1. Create Document node
            document_id = str(uuid.uuid4())

            document_query = """
            MERGE (doc:Document {file_hash: $file_hash})
            SET doc += {
                document_id: $document_id,
                filename: $filename,
                file_path: $file_path,
                file_size: $file_size,
                upload_date: datetime(),
                framework_type: $framework_type,
                status: 'ingested',
                industry: $industry
            }
            RETURN doc
            """

            graph.query(
                document_query,
                {
                    "document_id": document_id,
                    "file_hash": doc_metadata.get("file_hash", ""),
                    "filename": doc_metadata.get("filename", ""),
                    "file_path": doc_metadata.get("file_path", ""),
                    "file_size": doc_metadata.get("file_size", 0),
                    "framework_type": framework_type,
                    "industry": industry,
                },
            )

            # 2. Create RegulatoryBody node
            regulatory_body_id = str(uuid.uuid4())
            regulatory_body_data = extracted_data.get("regulatory_body", {})

            regulatory_body_query = """
            MERGE (rb:RegulatoryBody {id: $regulatory_body_id})
            SET rb += {
                name: $name,
                description: $description,
                authority_type: $authority_type,
                created_date: datetime()
            }
            RETURN rb
            """

            graph.query(
                regulatory_body_query,
                {
                    "regulatory_body_id": regulatory_body_id,
                    "name": regulatory_body_data.get(
                        "name", f"{framework_type} Authority"
                    ),
                    "description": regulatory_body_data.get("description", ""),
                    "authority_type": regulatory_body_data.get(
                        "authority_type", "Standards Organization"
                    ),
                },
            )
            stats["regulatory_bodies"] = 1

            # 2. Create Framework node
            framework_id = str(uuid.uuid4())
            framework_data = extracted_data.get("framework", {})

            framework_query = """
            MERGE (f:Framework {id: $framework_id})
            SET f += {
                name: $name,
                version: $version,
                source_document: $source_document,
                description: $description,
                publication_date: $publication_date,
                scope: $scope,
                created_date: datetime()
            }
            RETURN f
            """

            graph.query(
                framework_query,
                {
                    "framework_id": framework_id,
                    "name": framework_data.get("name", framework_type),
                    "version": framework_data.get("version", "1.0"),
                    "source_document": doc_metadata.get("filename", ""),
                    "description": framework_data.get("description", ""),
                    "publication_date": framework_data.get("publication_date", ""),
                    "scope": framework_data.get("scope", ""),
                },
            )
            stats["frameworks"] = 1

            # 3. Create Industry node
            industry_id = str(uuid.uuid4())
            industry_data = extracted_data.get("industry", {})

            industry_query = """
            MERGE (i:Industry {name: $industry_name})
            ON CREATE SET i.id = $industry_id,
                         i.created_date = datetime()
            RETURN i
            """

            graph.query(
                industry_query,
                {
                    "industry_id": industry_id,
                    "industry_name": industry_data.get("primary_industry", industry),
                },
            )
            stats["industries"] = 1

            # 4. Create RegulatoryBody -> Framework relationship
            rb_to_framework_query = """
            MATCH (rb:RegulatoryBody {id: $regulatory_body_id})
            MATCH (f:Framework {id: $framework_id})
            MERGE (rb)-[:PUBLISHES]->(f)
            """

            graph.query(
                rb_to_framework_query,
                {
                    "regulatory_body_id": regulatory_body_id,
                    "framework_id": framework_id,
                },
            )
            # Count relationship creation attempts (approximate via MERGE calls)
            stats["relationships_created"] += 1

            # Create Document relationships
            # Document -> Framework relationship (schema: EXTRACTED_TO)
            doc_to_framework_query = """
            MATCH (doc:Document {file_hash: $file_hash})
            MATCH (f:Framework {id: $framework_id})
            MERGE (doc)-[:EXTRACTED_TO]->(f)
            """

            graph.query(
                doc_to_framework_query,
                {
                    "file_hash": doc_metadata.get("file_hash", ""),
                    "framework_id": framework_id,
                },
            )
            stats["relationships_created"] += 1

            # Note: Document -> Industry relationship is not defined in schema.

            # 5. Create Control nodes with hierarchical sub-control support
            controls = extracted_data.get("controls", [])
            for control_data in controls:
                control_id = str(uuid.uuid4())
                control_ref_id = control_data.get("control_id") or ""
                if not isinstance(control_ref_id, str):
                    control_ref_id = str(control_ref_id)
                control_ref_id = control_ref_id.strip()
                # Ensure every control has a stable reference id used for mapping
                if not control_ref_id:
                    control_ref_id = f"AUTO-{uuid.uuid4().__str__()[:8].upper()}"
                    # Mutate source data so mapper sees the new id
                    control_data["control_id"] = control_ref_id

                # Create main Control node
                control_query = """
                MERGE (c:Control {id: $control_id})
                SET c += {
                    control_id: $control_ref_id,
                    name: $name,
                    description: $description,
                    control_type: $control_type,
                    framework_reference: $framework_reference,
                    implementation_guidance: $implementation_guidance,
                    is_sub_control: false,
                    created_date: datetime()
                }
                RETURN c
                """

                graph.query(
                    control_query,
                    {
                        "control_id": control_id,
                        "control_ref_id": control_ref_id,
                        "name": control_data.get("name", ""),
                        "description": control_data.get("description", ""),
                        "control_type": control_data.get("control_type", "Preventive"),
                        "framework_reference": framework_type,
                        "implementation_guidance": control_data.get(
                            "implementation_guidance", ""
                        ),
                    },
                )

                # Create sub-controls if they exist
                sub_controls = control_data.get("sub_controls", [])
                for i, sub_control_desc in enumerate(sub_controls):
                    if isinstance(sub_control_desc, str) and sub_control_desc.strip():
                        sub_control_id = str(uuid.uuid4())
                        sub_control_ref_id = (
                            f"{control_ref_id}.{i+1}"
                            if control_ref_id
                            else f"SUB-{i+1}"
                        )

                        # Create sub-control node
                        sub_control_query = """
                        MERGE (sc:Control {id: $sub_control_id})
                        SET sc += {
                            control_id: $sub_control_ref_id,
                            name: $name,
                            description: $description,
                            control_type: $control_type,
                            framework_reference: $framework_reference,
                            is_sub_control: true,
                            parent_control_id: $parent_control_id,
                            created_date: datetime()
                        }
                        RETURN sc
                        """

                        graph.query(
                            sub_control_query,
                            {
                                "sub_control_id": sub_control_id,
                                "sub_control_ref_id": sub_control_ref_id,
                                "name": f"{control_data.get('name', 'Control')} - Sub-control {i+1}",
                                "description": sub_control_desc,
                                "control_type": control_data.get(
                                    "control_type", "Preventive"
                                ),
                                "framework_reference": framework_type,
                                "parent_control_id": control_ref_id,
                            },
                        )

                        # Create HAS_SUBCONTROL relationship
                        subcontrol_rel_query = """
                        MATCH (parent:Control {id: $parent_id})
                        MATCH (sub:Control {id: $sub_id})
                        MERGE (parent)-[:HAS_SUBCONTROL]->(sub)
                        """

                        graph.query(
                            subcontrol_rel_query,
                            {
                                "parent_id": control_id,
                                "sub_id": sub_control_id,
                            },
                        )
                        stats["relationships_created"] += 1

                        # Connect sub-control to Framework
                        framework_to_subcontrol_query = """
                        MATCH (f:Framework {id: $framework_id})
                        MATCH (sc:Control {id: $sub_control_id})
                        MERGE (f)-[:CONTAINS]->(sc)
                        """

                        graph.query(
                            framework_to_subcontrol_query,
                            {
                                "framework_id": framework_id,
                                "sub_control_id": sub_control_id,
                            },
                        )
                        stats["relationships_created"] += 1

                        # Connect sub-control to Industry
                        subcontrol_to_industry_query = """
                        MATCH (sc:Control {id: $sub_control_id})
                        MATCH (i:Industry {name: $industry_name})
                        MERGE (sc)-[:APPLIES_TO]->(i)
                        """

                        graph.query(
                            subcontrol_to_industry_query,
                            {
                                "sub_control_id": sub_control_id,
                                "industry_name": industry_data.get(
                                    "primary_industry", industry
                                ),
                            },
                        )
                        stats["relationships_created"] += 1

                        stats["controls"] += 1

                # Create Framework -> Control relationship
                framework_to_control_query = """
                MATCH (f:Framework {id: $framework_id})
                MATCH (c:Control {id: $control_id})
                MERGE (f)-[:CONTAINS]->(c)
                """

                graph.query(
                    framework_to_control_query,
                    {"framework_id": framework_id, "control_id": control_id},
                )
                stats["relationships_created"] += 1

                # Create Control -> Industry relationship
                control_to_industry_query = """
                MATCH (c:Control {id: $control_id})
                MATCH (i:Industry {name: $industry_name})
                MERGE (c)-[:APPLIES_TO]->(i)
                """

                graph.query(
                    control_to_industry_query,
                    {
                        "control_id": control_id,
                        "industry_name": industry_data.get(
                            "primary_industry", industry
                        ),
                    },
                )
                stats["relationships_created"] += 1

                stats["controls"] += 1

            # Update controls_count for display purposes
            stats["controls_count"] = stats["controls"]

            return stats

        except Exception as e:
            st.error(f"Error creating schema nodes: {e}")
            return stats

    def _map_controls_to_techniques(
        self, graph, controls: List[Dict], framework_type: str = "", industry: str = ""
    ) -> int:
        """
        Map controls to ATT&CK techniques based on LLM-suggested mappings.

        Args:
            graph: Neo4j database connection
            controls: List of control dictionaries with potential technique mappings

        Returns:
            Number of technique mappings created
        """
        mappings_created = 0

        try:
            # Determine preferred domains once (used as heuristic)
            preferred_domains = self._determine_preferred_domains(
                framework_type, industry
            )

            for control in controls:
                potential_techniques = control.get("potential_attack_techniques", [])

                for technique_id in potential_techniques:
                    if not technique_id:
                        continue
                    tech_code = str(technique_id).strip().upper()
                    # Basic normalization: remove common wrappers and spaces
                    tech_code = tech_code.replace(" ", "").strip("[](){};,")
                    if not tech_code.startswith("T"):
                        continue

                    control_ref = control.get("control_id", "")

                    # Try mapping in domain preference order
                    mapped = False
                    for domain in preferred_domains:
                        if "." in tech_code:
                            # SubTechnique first; then fallback to parent Technique
                            parent_code = tech_code.split(".")[0]
                            # Attempt sub-technique mapping
                            sub_q = """
                            MATCH (c:Control {control_id: $control_id})
                            MATCH (st:SubTechnique {technique_id: $technique_id, domain: $domain})
                            MERGE (c)-[:MITIGATES]->(st)
                            RETURN count(st) AS matched
                            """
                            res = graph.query(
                                sub_q,
                                {
                                    "control_id": control_ref,
                                    "technique_id": tech_code,
                                    "domain": domain,
                                },
                            )
                            matched = res and res[0].get("matched", 0) > 0
                            if matched:
                                mappings_created += 1
                                mapped = True
                                break

                            # Fallback to parent Technique in same domain
                            par_q = """
                            MATCH (c:Control {control_id: $control_id})
                            MATCH (t:Technique {technique_id: $parent_id, domain: $domain})
                            MERGE (c)-[:MITIGATES]->(t)
                            RETURN count(t) AS matched
                            """
                            res2 = graph.query(
                                par_q,
                                {
                                    "control_id": control_ref,
                                    "parent_id": parent_code,
                                    "domain": domain,
                                },
                            )
                            matched2 = res2 and res2[0].get("matched", 0) > 0
                            if matched2:
                                mappings_created += 1
                                mapped = True
                                break
                        else:
                            # Technique mapping
                            tech_q = """
                            MATCH (c:Control {control_id: $control_id})
                            MATCH (t:Technique {technique_id: $technique_id, domain: $domain})
                            MERGE (c)-[:MITIGATES]->(t)
                            RETURN count(t) AS matched
                            """
                            res = graph.query(
                                tech_q,
                                {
                                    "control_id": control_ref,
                                    "technique_id": tech_code,
                                    "domain": domain,
                                },
                            )
                            matched = res and res[0].get("matched", 0) > 0
                            if matched:
                                mappings_created += 1
                                mapped = True
                                break

                    # If not mapped in preferred domains, try the other domain as a last resort
                    if not mapped:
                        fallback_domains = [
                            d
                            for d in ["enterprise", "ics"]
                            if d not in preferred_domains
                        ] + preferred_domains
                        for domain in fallback_domains:
                            if "." in tech_code:
                                parent_code = tech_code.split(".")[0]
                                par_q = """
                                MATCH (c:Control {control_id: $control_id})
                                MATCH (t:Technique {technique_id: $parent_id, domain: $domain})
                                MERGE (c)-[:MITIGATES]->(t)
                                RETURN count(t) AS matched
                                """
                                res = graph.query(
                                    par_q,
                                    {
                                        "control_id": control_ref,
                                        "parent_id": parent_code,
                                        "domain": domain,
                                    },
                                )
                                if res and res[0].get("matched", 0) > 0:
                                    mappings_created += 1
                                    break
                            else:
                                tech_q = """
                                MATCH (c:Control {control_id: $control_id})
                                MATCH (t:Technique {technique_id: $technique_id, domain: $domain})
                                MERGE (c)-[:MITIGATES]->(t)
                                RETURN count(t) AS matched
                                """
                                res = graph.query(
                                    tech_q,
                                    {
                                        "control_id": control_ref,
                                        "technique_id": tech_code,
                                        "domain": domain,
                                    },
                                )
                                if res and res[0].get("matched", 0) > 0:
                                    mappings_created += 1
                                    break

        except Exception as e:
            st.warning(f"Warning in technique mapping: {e}")

        return mappings_created

    def _fallback_map_controls(
        self, graph, controls: List[Dict], framework_type: str, industry: str
    ) -> int:
        """As a last resort, extract T-codes from control text and map at least once."""
        import re

        preferred = self._determine_preferred_domains(framework_type, industry)
        # Pick first control with some text
        for control in controls:
            text = " ".join(
                [
                    str(control.get("name", "")),
                    str(control.get("description", "")),
                    str(control.get("implementation_guidance", "")),
                ]
            )
            matches = re.findall(r"T\d{4}(?:\.\d{3})?", text, flags=re.IGNORECASE)
            if not matches:
                continue
            # Use first match
            tech_code = matches[0].upper()
            control_ref = control.get("control_id") or ""
            if not control_ref:
                continue
            # Try preferred domains
            for domain in preferred:
                if "." in tech_code:
                    parent = tech_code.split(".")[0]
                    sub_q = """
                    MATCH (c:Control {control_id: $control_id})
                    MATCH (st:SubTechnique {technique_id: $tech_code, domain: $domain})
                    MERGE (c)-[:MITIGATES]->(st)
                    RETURN count(st) AS matched
                    """
                    res = graph.query(
                        sub_q,
                        {
                            "control_id": control_ref,
                            "tech_code": tech_code,
                            "domain": domain,
                        },
                    )
                    if res and res[0].get("matched", 0) > 0:
                        return 1
                    par_q = """
                    MATCH (c:Control {control_id: $control_id})
                    MATCH (t:Technique {technique_id: $parent, domain: $domain})
                    MERGE (c)-[:MITIGATES]->(t)
                    RETURN count(t) AS matched
                    """
                    res2 = graph.query(
                        par_q,
                        {"control_id": control_ref, "parent": parent, "domain": domain},
                    )
                    if res2 and res2[0].get("matched", 0) > 0:
                        return 1
                else:
                    tech_q = """
                    MATCH (c:Control {control_id: $control_id})
                    MATCH (t:Technique {technique_id: $tech_code, domain: $domain})
                    MERGE (c)-[:MITIGATES]->(t)
                    RETURN count(t) AS matched
                    """
                    res = graph.query(
                        tech_q,
                        {
                            "control_id": control_ref,
                            "tech_code": tech_code,
                            "domain": domain,
                        },
                    )
                    if res and res[0].get("matched", 0) > 0:
                        return 1
        # Final safety: try a very common enterprise technique if present
        common = "T1082"  # System Information Discovery
        for domain in preferred + [
            d for d in ["enterprise", "ics"] if d not in preferred
        ]:
            q = """
            MATCH (t:Technique {technique_id: $tech, domain: $domain}) RETURN count(t) AS c
            """
            res = graph.query(q, {"tech": common, "domain": domain})
            if res and res[0].get("c", 0) > 0 and controls:
                cref = controls[0].get("control_id")
                if cref:
                    map_q = """
                    MATCH (c:Control {control_id: $control_id})
                    MATCH (t:Technique {technique_id: $tech, domain: $domain})
                    MERGE (c)-[:MITIGATES]->(t)
                    RETURN 1 as ok
                    """
                    graph.query(
                        map_q, {"control_id": cref, "tech": common, "domain": domain}
                    )
                    return 1
        return 0

    def _extract_document_metadata(self, file_path: str) -> Dict[str, Any]:
        """Extract metadata from document file."""
        with open(file_path, "rb") as file:
            content = file.read()
            file_hash = hashlib.sha256(content).hexdigest()

        return {
            "filename": os.path.basename(file_path),
            "file_path": os.path.abspath(file_path),
            "file_hash": file_hash,
            "ingested_date": datetime.now().isoformat(),
            "file_size": len(content),
        }

    def _is_document_ingested(self, graph, file_hash: str) -> bool:
        """Check if document is already ingested."""
        # Use WHERE to avoid map literal property warning on first run
        query = "MATCH (d:Document) WHERE d.file_hash = $file_hash RETURN d LIMIT 1"
        result = graph.query(query, {"file_hash": file_hash})
        return len(result) > 0

    def _ensure_document_placeholder(self, graph, doc_metadata: Dict[str, Any]) -> str:
        """Ensure a Document node exists with file_hash to avoid property warnings; return current status."""
        try:
            q = """
            MERGE (d:Document {file_hash: $file_hash})
            ON CREATE SET d.document_id = $document_id,
                          d.filename = $filename,
                          d.file_path = $file_path,
                          d.upload_date = datetime(),
                          d.status = 'pending'
            RETURN COALESCE(d.status, 'pending') AS status
            """
            res = graph.query(
                q,
                {
                    "file_hash": doc_metadata.get("file_hash", ""),
                    "document_id": str(uuid.uuid4()),
                    "filename": doc_metadata.get("filename", ""),
                    "file_path": doc_metadata.get("file_path", ""),
                },
            )
            return (res[0]["status"] if res else "pending") or "pending"
        except Exception:
            return "pending"

    def _determine_preferred_domains(
        self, framework_type: str, industry: str
    ) -> List[str]:
        """Heuristic to pick domain preference for ATT&CK mapping (enterprise vs ics)."""
        ft = (framework_type or "").lower()
        ind = (industry or "").lower()
        ics_signals = [
            "ics",
            "ot",
            "industrial",
            "scada",
            "nist sp 800-82",
            "critical infrastructure",
        ]
        ics_industries = [
            "energy",
            "utilities",
            "manufactur",
            "oil",
            "gas",
            "water",
        ]
        if any(sig in ft for sig in ics_signals) or any(
            sig in ind for sig in ics_industries
        ):
            return ["ics", "enterprise"]
        return ["enterprise", "ics"]

    def _extract_pdf_content(self, file_path: str) -> str:
        """Extract text content from PDF file."""
        try:
            content = ""
            with open(file_path, "rb") as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page_num in range(len(pdf_reader.pages)):
                    page = pdf_reader.pages[page_num]
                    content += page.extract_text() + "\n"
            return content.strip()
        except Exception as e:
            st.error(f"Error extracting PDF content: {e}")
            return ""

    def _update_ingestion_status(
        self, framework_type: str, doc_metadata: Dict, stats: Dict
    ):
        """Update the ingestion status file with improved framework key normalization."""
        try:
            status_file = "src/config/ingestion_status.json"

            # Load existing status
            if os.path.exists(status_file):
                with open(status_file, "r") as f:
                    status = json.load(f)
            else:
                status = {
                    "ingested_documents": [],
                    "ingested_frameworks": {},
                    "total_nodes": 0,
                    "last_updated": None,
                }

            # Update document tracking
            doc_info = {
                "filename": doc_metadata["filename"],
                "framework_type": framework_type,
                "file_hash": doc_metadata["file_hash"],
                "ingested_date": doc_metadata["ingested_date"],
                "controls_count": stats.get("controls", 0),
            }
            status["ingested_documents"].append(doc_info)

            # Normalize framework key for consistent tracking
            # Convert to lowercase, replace special chars with underscores, remove extra spaces
            framework_key = (
                framework_type.lower()
                .replace(" ", "_")
                .replace("(", "")
                .replace(")", "")
                .replace("-", "_")
                .replace(".", "_")
                .replace(",", "")
                .replace("&", "and")
            )

            # Remove duplicate underscores
            while "__" in framework_key:
                framework_key = framework_key.replace("__", "_")

            # Remove leading/trailing underscores
            framework_key = framework_key.strip("_")

            # Update framework tracking
            if framework_key not in status["ingested_frameworks"]:
                status["ingested_frameworks"][framework_key] = {
                    "status": "ingested",
                    "documents": [],
                    "last_updated": datetime.now().isoformat(),
                    "framework_display_name": framework_type,  # Store original display name
                    "node_counts": {
                        "regulatory_bodies": 0,
                        "frameworks": 0,
                        "controls": 0,
                        "industries": 0,
                    },
                }

            # Update counts
            framework_status = status["ingested_frameworks"][framework_key]
            framework_status["documents"].append(doc_metadata["filename"])
            framework_status["last_updated"] = datetime.now().isoformat()
            framework_status["framework_display_name"] = (
                framework_type  # Update display name
            )

            for key in ["regulatory_bodies", "frameworks", "controls", "industries"]:
                framework_status["node_counts"][key] += stats.get(key, 0)

            # Update total nodes estimate
            status["total_nodes"] += sum(stats.values())
            status["last_updated"] = datetime.now().isoformat()

            # Save updated status
            with open(status_file, "w") as f:
                json.dump(status, f, indent=2)

        except Exception as e:
            st.warning(f"Could not update ingestion status: {e}")
